---
title: Synthetic Data
description: TBD.
categories: ml
date: 2024-02-25
last_modified_at: 2024-02-25
layout: post
permalink: /:categories/:title
---

Here are my notes on synthetic data. Take it with grain of salt, as I am new in this area.

Let's say you have a generative AI (generative machine learning) problem, so you have some input data, and some corresponding output data.
But you have only a small quantity of this data.

Synthetic data helps where you need to add missing hard to collect data needed for your predictions.
This data could be something people never write down or say.
For example human thoughts when problem-solving usually don't get written down.

The rarer and more important the data the more important the synthetic data can be.

If nothing like this data was present during the model pretraining, you won't be able to prompt-instruct the model to perform this.
Few shot examples can help, but the more complex the problem, the more likely you will need more examples, which are costly to write by hand.

Another way of looking at this, is that you can use 

## Why synthetic data makes sense?
Real data costs human time and synthetic data can be a way around that.
But you cannot create the required data out of thin air synthetically.

You may need:
1. either more general model that was essentially trained one something similar to the target data needed,
2. or you need a real data that is close to the required data, and perform only an easy modification to match the required data distribution.

Another way of looking at 2, is that you can use other data, which was trained into LLM to shift the output distribution the way you want.
For example in a way polishing the LLM behaviour by making it consistent with selected good patterns in the other data,
which are extracted and applied with instructions, which leads to generation of good synthetic data.



## Verification of Synthetic Data
Garbage-in implies garbage-out.
The more difficult data to generate or more distant to the real training data, the harder it is to synthesize correct data to train on.

In some problems verification is easier that generation, so in these cases you can remove the invalid data out of the generated data.
For example, the goal may be to generate a program function that passes an executable set or tests.
In this case, it is very easy to verify that the generated summation is correct.

In some cases, it is easy to generate the questions (inputs) given the answers (outputs).
This inverted generation also allows you to control for the distribution of the labeled samples.
For example, for text classification, it may be easier to generate a text that matches given category label.
Another example of this method is [Self-Alignment with Instruction Backtranslation](https://arxiv.org/abs/2308.06259).


## Levels of Synthetic Data
Here is a spectrum of increasingly less human involvement in the process or human leverage in the process or model development.

1. Fully manual: You would love to train on data from people that is fully manually written and verified.
2. Cleaned up manual data: The data is manually written, but rewritten, rephrased or cleaned by a machine, then verified.  
3. The data is entirely generated, but manually verified and select each sample and labelled.
4. The data is entirely generated, and rated by a machine. Trained model is evaluated on a small human labelled subset.
5. Self-aligning or self-polishing: The data is entirely generated, and rated by a machine. Trained model is evaluated on a machine generated data.
6. Autonomous: Self-improving from environment and from generated data. The [Q-transformer](/ml/Bellman-Update-and-Synthetic-Data-in-Q-Transformer) is a step towards that.


## Examples of Synthetic Data Applications

### [Teknium's Nous-Hermes-2-Mistral-7B-DPO](https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO)

Nous-Hermes-2-Mistral-7B-DPO was trained on:
- SFT synthetic dataset teknium/OpenHermes-2.5 generated by GPT-4 in size of 1,000,000 instructions/chats in .
- Some unknown DPO dataset, which likely is also GPT-4 generated


### [DSPy](https://github.com/stanfordnlp/dspy?tab=readme-ov-file) (Python Library)
DSPy can fine-tune smaller models on using small amount of labelled examples and prompting to generate synthetic fine-tuning data.

In general this library helps you to build prompt chains or pipelines where the LLMs have well-defined inputs and outputs, and various tools like RAG. 

The library abstracts away fine changes to the prompt of prompt engineering and instead optimizes the prompts for you, such that you only focus on structured and documented inputs and outputs.
In this it seems much more practical than LangChain.

The library generates few-shot examples for you prompt-chain steps for you and call this step compiling.
For example, it can generate reasoning examples and so on.
Question for is, how good the examples are?
Un-compiled chains use zero-shot prompting.

Here is an example project in [a video](https://www.youtube.com/watch?v=41EfOY0Ldkc). 


## Research Papers Relevant to Synthetic Data
This is not exhaustive list and I may expand on this in the future.

### [Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision](https://arxiv.org/html/2312.09390v1)
Smaller model teacher model, generates inputs, and labels.
The bigger model can learn to outperform the smaller teacher, if allowed to be "over-confident".
However, I think this approach is not generally proven for all situations and still seems to show upper performance limit.

### [Let's Verify Step by Step](https://arxiv.org/abs/2305.20050)
A math reasoning dataset.
Contributions of this paper are: 

1. process supervision can train much more reliable reward models than outcome supervision. State-of-the-art process-supervised reward model solves 78.2% of problems from a representative subset of the MATH test set.
2. a large reward model can reliably approximate human supervision for smaller reward models, and that it can be used to efficiently conduct large-scale data collection ablations.
3. active learning leads to a 2.6Ã— improvement in the data efficiency of process supervision.
4. full process supervision dataset, PRM800K, a dataset of 800K step-level labels across 75K solutions to 12K problems). Assign each step in the solution a label of positive, negative, or neutral.


### [WizardLM Evol Instruct](https://github.com/nlpxucan/WizardLM)
Use human written coding examples to generate more difficult (complex) examples with GPT-3.5.
Use this sythetic dataset to fine-tune and improve performance on coding problems.


### [Constitutional AI](https://arxiv.org/abs/2212.08073)
Use LLM to label generated responses to follow certain rules (constitution about harm, bias, and more).