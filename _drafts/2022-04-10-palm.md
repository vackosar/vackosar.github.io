---
title: "PaLM"
description: "lang model"
layout: post
categories: ml
date: 2022-04-10
permalink: /:categories/:title
---

{% include mathjax.html %}

Pathways Language Model (PaLM) is a 540-billion parameter with architecture akin to GPT-3.
This model, published April 4th, 2022, achieves breakthrough capabilities on language understanding and generation, reasoning, and coding tasks.
For example for reasoning tasks, PaLM used chain-of-thought prompting, which applies simulated inner monologue to solve grade school level math questions.
In this talk, Vaclav will discuss both general-public-accessible intuition of how knowledge and reasoning can be represented in computers as well as technical details of PaLM model architecture.

## Intro
- at the begging there was a word
- in a vocabulary
- counting methods
- gradient methods
- vector methods
    - Tao te ching - every positive tjoight negative - direction and anti direction
- RNNs
- Transfomers
- knowledge graph - what is knowledge
  - wikipedia is knowledge graph
  - knowledge graph is between database and training data samples
- softmax forces to make a decision, a collapse
- projection and subspaces
- last 230 iq person

## Summary
- 540-billion parameters
- 2x bigger than GPT-3 175B
- 2x smaller than [Switch Transformer](https://arxiv.org/pdf/2101.03961.pdf) 1T
  - only parts of the model is activated at each time.
- human brain 100T connections
- but the most [expensive model trained ~$10M](https://blog.heim.xyz/palm-training-cost/)
- these models are mostly like a race cars: fascinating, but not really practical
- results suggest that the improvements from scale for few-shot language understanding have not yet plateaued

- highly efficient training on 6144 TPU v4 chips across multiple cluster TPU Pods
- discontinuous improvements: disproportionate jumps in accuracy from 62B to 540 compared to 8B to 62B
- breakthrough performance without fine-tuning
- breakthrough performance outperforming average human on BIG-bench benchmark
- for reasoning, PaLM uses chain-of-thought prompting, which simulates human reasoning inner monologue applied to grade school level math questions.


## Zero-Shot and Few-Shot Prompting
- zero-shot - do not describe the task, but no examples given
- few-shot: randomly sample examples, and then request the target example 


## Breakthrough Capabilities
- when combined with chain-of-thought prompting
- few-shot evaluation outperforms fine-tuned previous SOTA
- BIG-bench is 150+ tasks
- 58 tasks comparable to other models
- many are multiple choice questions
- PaLM is SOTA outperforming GPT-3 and human average
- still underperforms average human on many tasks
- funny footnote: the dataset is scanned for in the training set using GUID
- certain capabilities of the model only emerge once a certain scale is reached

![discontinuous improvements with scale](/images/palm-discontinuous-improvement-with-scale.png)


## Chain of Thought Prompting
- chain of thought prompting teaches reasoning steps
- akin to execution 
- multi-step arithmetic
  - grade-school level math problems
  - difficult is to convert to equations
- commonsense logical reasoning
  - strong world knowledge
  - chaining logical inferences
- thoughts are useful for interpretation

![Chain of Thought Prompting](/images/palm-chain-of-though-prompting.png)


## Chain of Thought Prompting Results
- reasoning tasks datasets: GSM8K, SVAMP, MAWPS, AQuA, CommonsenseQA, StrategyQA
- on GSM8K: PaLM+chain-of-thought competitive with GPT-3+finetuning+calculator+verifier 
- generating explicit inference chains drastically increase the quality of the predictions
- TODO how added calculator?

![PaLM chain of thought prompting new SOTA on GSM8K, MAWPS, SVAMP, and StrategyQA](/images/palm-chain-of-though-prompting-results.png)


## Explanations
- do thoughts represent right reasons?
- even desired output
- 2-shot experiment below
- greedy decoding,
- not in paper: I added GPT-3, results with zero-temperature

TODO fix below
 
Input: _Jennifer looked out her window and sees a really cool cloud below her. She unbuckles her seatbelt and heads to the bathroom. Is Jennifer probably traveling more than 300 miles per hour relative to the earth?_

PaLM: __300 miles per hour is about 480 km/h. This is about the speed of a commercial airplane. Clouds are usually below airplanes, so Jennifer is probably on an airplane. The answer is "yes"__

GPT-3: __No, because an airplane typically travels around 500-600 miles per hour, and the bathroom is usually located in the back of the plane.__

## Explanations on GPT-3
- I payed GPT-3 and experimented 
- exact same prompt as in the paper
- GPT-3 Output: "The person in the joke is not excited about their step dad's poetry reading. They would rather fly in on a different day to avoid it."
- We can infer that Jennifer is on an airplane because she is looking out a window and sees a cloud below her. We can also infer that she is traveling at a high speed because she is on an airplane. The average cruising speed of an airplane is about 550 miles per hour, so Jennifer is probably traveling more than 300 miles per hour relative to the earth. The answer is "yes".
- We can infer that Jennifer is in an airplane because she is looking out a window. We can also infer that she is high up in the sky because she can see a cloud "below" her. Clouds are usually found at altitudes above 3,000 feet. Finally, we know that airplanes typically travel around 500 miles per hour. So, Jennifer is probably traveling more than 300 miles per hour, but we cannot be certain. The answer is "yes".

## PaLM on Code Tasks
- achieves similar results to specialized model Codex 12B with 3% of the code training data
- after fine-tuning outperforms Davinci Codex

![PaLM and PaLM-Coder models scales 8B, 62B and 540B](/images/palm-coding-tasks-results.png)


## Other Tasks
- but also too expensive to be practical 
- generally SOTA on few-shot variants but few-shot not competitive with specialized fine-tuned variants
- fine-tuned only competitive with specialized fine-tuned variants
- translation: without fine-tuning outperforms GPT-3, outperforms some supervised baselines de-en, ro-en
- natural language generation summarization: fine-tuned results competitive, few-shot largely underperformed of fine-tuned
- multilingual question answering: fine-tuned results competitive, few-shot largely underperformed of fine-tuned 

[palm multilingual question answering results](/images/palm-multilingual-question-answering-results.png)


## Architecture:
- decoder-only transformer (attending only to the past) like GPT-3
- modified Feed-forward layer (MLP):
  - original: \\( max(0, xW_1 + b_1)W_2 + b_2 \\) 
  - instead: [SwiGLU feed-foward](https://arxiv.org/pdf/2002.05202.pdf)
  - better in compute equivalent setup
  - uses GLU: gated linear unit - a sigmoid controlled output
  - SwiGLU: \\( \mathrm{FFN}_{\mathrm{SwiGLU}} := (\mathrm{Swish}(xW_1) \otimes xV ) W_2 \\)
  - uses [swish activation](https://arxiv.org/pdf/1710.05941v1.pdf?source=post_page): \\( x (1 + exp(−x))^{−1} \\)
- parallel Attention and Feed-forward layer (MLP) from [GPT-J](https://github.com/kingoflolz/mesh-transformer-jax):
  - \\( y = x + MLP(LayerNorm(x)) + Attention(LayerNorm(x)) \\)
  - 15% speedup for small degradation
- [multi-query attention](https://arxiv.org/pdf/1911.02150.pdf):
  - block-shared key and value projections, different query projections
  - speeds up autoregressive decoding
- [RoPE Embeddings](https://arxiv.org/pdf/2104.09864.pdf):
  - want relative position info in query-value dot-product
  - use multiplicative rotational matrix mixing pairwise neighboring dimensions
  - improves performance on long sequence lengths

## Training Dataset
- 780 billion tokens of high-quality text but private
- social media 50%, webpages 27%, books 13%, wikipedia 4%, code 5%, news 1%
- based on dataset used for LaMBDA, GLaM
- private non-reproducible dataset
- MT-NLG used 339B tokens reproducible dataset non-hosted

![PaLM dataset hierarchical topics](/images/PaLM-dataset-hierarchical-topics.png)


## Efficient Scaling
- mind of PalM is shattered across many chips
- ~17 TB of RAM needed for training
- 2 TPU v4 Pod clusters connected data center network
- each Pod 
  - 768 hosts, 3072 TPU v4 chips
  - 1 exaflop/s 
- gives overview of the parallelism methods
 

## Training Large Scale Models
No worker has enough compute or memory to host large scale model.
Mainly because it is cheaper to buy many smaller machines: replaceable, easier to cool down.
But that requires us to split the computation to multiple processors, memories with limited communication.
In parallel computing we trade off 3 resources: compute ("time"), memory ("space"), communication throughput (no cool name).
Following strategies are used in large scale model training e.g. [Megatrong-Turing (Microsoft and NVidia)](https://arxiv.org/pdf/2201.11990.pdf): 

- data parallelism
  - batches are divided between works
- pipeline mechanism
  - splits model computation DAG into stages e.g. into layers
  - stages exchange forward and backward propagation information into micro-batches
  - step by step passing causes "bubble" of idle devices
- tensor model parallelism
  - splits model layers i.e. transformer block into attention heads and feedforward

![NVIDIA data center DGX AI](/images/nvidia-data-center-dgx-ai.jpg)

## Training Infrastructure
- PaLM uses pipeline-free 2D parallelism
- data parallel across clusters "Pods"
- each cluster has full model copy
  - model partitioned into 12 parts
  - data partitioned into 256 parts
  - 1.5k hosts connected to 3k chips which are interconnected
- update to identical models after each batch
- each host exchanges 1.3GB with its counterpart

![Pathways system datacenter network, tpu ](/images/palm-pathways-system-datacenter-pods-hosts-TPU-chips.png)


## Training Efficiency
- observed throughput relative to the theoretical maximum throughput of a system
- price for parallelization of PaLM is 50%
- in case of PaLM throughput is tokens-per-second

![Model FLOPs utilization of PaLM vs Megatron-Turing NLG vs Gopher vs GPT-3](/images/PaLM-model-flop-utilization-vs-megatron-vs-gopher-gpt-3.png)


## Other notes - TODO cleanup
- blog https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html
- a 540-billion parameter, dense decoder-only Transformer model
- with breakthrough capabilities on language understanding and generation, reasoning, and code-related
- decoder-only Transformer ~ like GPT-3
- https://www.searchenginejournal.com/google-pathways-ai/428864/#close
- Title: 
	Google's Pathways Language Model and Chain-of-Thought
- Text:
	


## Appendix

### GPT-3 Explanations Full Prompts

#### Logical Inference 1
```
I will explain how to make logical inferences:
(1) John wakes to the sound of his children giggling outside the door. They bust in and say "Happy Father's Day!" with a plate full of food. 2022 has been a great year. Can we infer that John was born before the inauguration of Barack Obama?
Answer: We can infer that John is a father because of "his children". We can infer that the current year is 2022. Barack Obama was inaugurated in 2009, so it has been about 13 years since Obama was inaugurated. John's children are old enough to speak, so if John were born after Obama's inauguration, he would have been younger than 10 when he had children. So, we can infer that John was born before Obama's inauguration. The answer is "yes".
(2) Sam sees a piano in the subway stations. Laughing, his friends prod him to play, saying "Remember how amazing your rendition of Chopsticks was at the Christmas party?" Can we infer that John majored in piano at Juilliard?
Answer: Juilliard is a top school for music, so someone who majored in piano at Juilliard would be an expert pianist. "Chopsticks" is a very simple song to play on the piano. His friends were therefore likely being sarcastic when they told him to play, which would imply that Sam was not an expert piano player. So it is unlikely that Sam majored in piano at Juilliard. The answer is "no".
(3) Jennifer looked out her window and sees a really cool cloud below her. She unbuckles her seatbelt and heads to the bathroom. Is Jennifer probably traveling more than 300 miles per hour relative to the earth?
Answer:
```

Best of 2 temperature 0.7 otherwise defaults:
- We can infer that Jennifer is on an airplane because she is looking out a window and sees a cloud below her. We can also infer that she is traveling at a high speed because she is on an airplane. The average cruising speed of an airplane is about 550 miles per hour, so Jennifer is probably traveling more than 300 miles per hour relative to the earth. The answer is "yes".
- We can infer that Jennifer is in an airplane because she is looking out a window. We can also infer that she is high up in the sky because she can see a cloud "below" her. Clouds are usually found at altitudes above 3,000 feet. Finally, we know that airplanes typically travel around 500 miles per hour. So, Jennifer is probably traveling more than 300 miles per hour, but we cannot be certain. The answer is "yes".

Greedy:
- No, because an airplane typically travels around 500-600 miles per hour, and the bathroom is usually located in the back of the plane.


#### Logical Inference 2
```
I will explain how to make logical inferences:
(1) John wakes to the sound of his children giggling outside the door. They bust in and say "Happy Father's Day!" with a plate full of food. 2022 has been a great year. Can we infer that John was born before the inauguration of Barack Obama?
Answer: We can infer that John is a father because of "his children". We can infer that the current year is 2022. Barack Obama was inaugurated in 2009, so it has been about 13 years since Obama was inaugurated. John's children are old enough to speak, so if John were born after Obama's inauguration, he would have been younger than 10 when he had children. So, we can infer that John was born before Obama's inauguration. The answer is "yes".
(2) Sam sees a piano in the subway stations. Laughing, his friends prod him to play, saying "Remember how amazing your rendition of Chopsticks was at the Christmas party?" Can we infer that John majored in piano at Juilliard?
Answer: Juilliard is a top school for music, so someone who majored in piano at Juilliard would be an expert pianist. "Chopsticks" is a very simple song to play on the piano. His friends were therefore likely being sarcastic when they told him to play, which would imply that Sam was not an expert piano player. So it is unlikely that Sam majored in piano at Juilliard. The answer is "no".
(3) Shelley is from Virginia, but is visiting that city with that famous market where they throw the fish. Going home next Tuesday!
Question: Is it likely that Shelley will be near the Pacific Ocean this weekend?
Answer: 
```

Best of 2, temperature 0.7 otherwise defaults:
- It is not likely that Shelley will be near the Pacific Ocean this weekend. Shelley is from Virginia, which is on the East Coast of the United States. The city with the famous fish market is most likely Seattle, which is also on the West Coast. Shelley is visiting, so she is not from there. She is going home next Tuesday, so she will likely be going back to Virginia this weekend.
- It is not likely that Shelley will be near the Pacific Ocean this weekend. Shelley is from Virginia, which is on the East Coast of the United States. The city with the famous fish market is most likely Seattle, which is also on the West Coast. Shelley is visiting, so she is not from there. She is going home next Tuesday, so she will likely be going back to Virginia this weekend.

Greedy:
- It is not likely that Shelley will be near the Pacific Ocean this weekend. Shelley is from Virginia, which is on the East Coast of the United States. The city with the famous fish market is most likely Seattle, which is also on the West Coast. Shelley is visiting, so she is not from there. She is going home next Tuesday, so she will likely be going back to Virginia this weekend.


#### Jokes
```
I will explain these jokes:
(1) The problem with kleptomaniacs is that they always take things literally.
Explanation: This joke is wordplay. Someone who "takes things literally" is someone who doesn't fully understand social cues and context, which is a negative trait.
But the definition of kleptomania is someone who literally takes things.
(2) Always borrow money from a pessimist. They’ll never expect it back.
Explanation: Most people expect you to pay them back when you borrow money, however a pessimist is someone who always assumes the worst, so if you borrow money from them, they will expect that you won't pay them back anyways.
(3) I was going to fly to visit my family on April 6th. My mom said "Oh great, your step dad's poetry reading is that night!" So now I'm flying in on April 7th.
Explanation:
```

Best of 2 temperature 0.7 otherwise defaults:
- This joke is about how annoying mothers can be. The speaker is trying to visit their family, but their mother has just informed them that their step-dad's poetry reading is on the same night. So now the speaker has to fly in on the next day.
- This joke is about how annoying it can be to have to deal with family obligations. The person telling the joke is trying to visit their family on April 6th, but their mom tells them that their step dad's poetry reading is that night. So the person has to fly in on April 7th instead.
- This joke is about how annoying and inconsiderate step-parents can be. The punchline is that the person is flying in a day later just to avoid their step-dad's poetry reading.

Greedy:
- This joke is about how annoying and intrusive in-laws can be. The person is trying to visit their family, but their mother says that their step-dad's poetry reading is that night. So the person is now flying in the next day to avoid it.